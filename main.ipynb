{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takes video and detects face to put rectangle around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n",
      "No faces detected!\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = vid.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    # print(face_locations)\n",
    "    if face_locations:\n",
    "        x, y, w, h = face_locations[0][0], face_locations[0][1], face_locations[0][2], face_locations[0][3]\n",
    "\n",
    "        rectangle_image = cv2.rectangle(frame, (h, x), (y, w), (255, 0, 0))\n",
    "\n",
    "        cv2.imshow(\"image\", rectangle_image)\n",
    "    else:\n",
    "        print(\"No faces detected!\")\n",
    "\n",
    "    # cv2.imshow('Video',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(136, 563, 226, 474), (136, 295, 226, 205)]\n",
      "136 563 226 474\n"
     ]
    }
   ],
   "source": [
    "image = face_recognition.load_image_file(\"jas.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "print(face_locations)\n",
    "x,y,w,h = face_locations[0][0],face_locations[0][1],face_locations[0][2],face_locations[0][3]\n",
    "print(x,y,w,h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"jas.jpg\")\n",
    "# cv2.imshow(\"image\",img)\n",
    "rectangle_image = cv2.rectangle(img, (h, x), (y, w), (255,0,0))\n",
    "cv2.imshow(\"image\",rectangle_image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
